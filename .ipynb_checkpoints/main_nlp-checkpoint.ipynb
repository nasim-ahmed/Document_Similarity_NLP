{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (3.5)\n",
      "Requirement already satisfied: joblib in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from nltk) (0.14.1)\n",
      "Requirement already satisfied: regex in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from nltk) (2020.10.11)\n",
      "Requirement already satisfied: click in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from nltk) (7.1.1)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from nltk) (4.50.2)\n",
      "\u001b[33mWARNING: You are using pip version 20.2; however, version 20.2.3 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: gensim in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (3.8.3)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from gensim) (3.0.0)\n",
      "Requirement already satisfied: six>=1.5.0 in /Users/nasim/Library/Python/3.8/lib/python/site-packages (from gensim) (1.14.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from gensim) (1.18.2)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from gensim) (1.4.1)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from smart-open>=1.8.1->gensim) (2.23.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests->smart-open>=1.8.1->gensim) (1.25.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests->smart-open>=1.8.1->gensim) (2.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests->smart-open>=1.8.1->gensim) (2019.11.28)\n",
      "\u001b[33mWARNING: You are using pip version 20.2; however, version 20.2.3 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/nasim/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'sun', 'rises', 'in', 'the', 'East', 'and', 'sets', 'in', 'the', 'west', '.']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Word tokenizations which basically splits a sentence into words\"\"\"\n",
    "\n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "data = \"The sun rises in the East and sets in the west.\"\n",
    "print(word_tokenize(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Earth is not a perfect sphere.', \"As Earth spins, gravity points toward the center of our planet (assuming for explanation's sake that Earth is a perfect sphere), and a centrifugal force pushes outward.\"]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Sentence tokenization is needed to count the average words per sentence. So we need to use to calculate the ratio\"\"\"\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "data = \"Earth is not a perfect sphere. As Earth spins, gravity points toward the center of our planet (assuming for explanation's sake that Earth is a perfect sphere), and a centrifugal force pushes outward.\"\n",
    "print(sent_tokenize(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 3\n",
      "['Mars is the fourth planet in our solar system.', 'It is second-smallest planet in the Solar System after Mercury.', 'Saturn is yellow planet.']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"File opening and sentence tokenization\"\"\"\n",
    "\n",
    "import nltk, gensim\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize \n",
    "\n",
    "\n",
    "file_docs = []\n",
    "\n",
    "with open('demofile1.txt') as f:\n",
    "    tokens = sent_tokenize(f.read())\n",
    "    for line in tokens: \n",
    "        file_docs.append(line)\n",
    "        \n",
    "print(\"Number of documents:\", len(file_docs))\n",
    "print(file_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mars', 'is', 'the', 'fourth', 'planet', 'in', 'our', 'solar', 'system', '.']\n",
      "{'.': 0, 'fourth': 1, 'in': 2, 'is': 3, 'mars': 4, 'our': 5, 'planet': 6, 'solar': 7, 'system': 8, 'the': 9, 'after': 10, 'it': 11, 'mercury': 12, 'second-smallest': 13, 'saturn': 14, 'yellow': 15}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"The next step is to tokenize into words and create a dictionary. It is important to convert the tokens into unique ids \n",
    "which then allows Genism to create a Dictionary object that maps each word to unique id\"\"\"\n",
    "\n",
    "gen_docs = [[w.lower() for w in word_tokenize(text)] for text in file_docs]\n",
    "print(gen_docs[0])\n",
    "\n",
    "dictionary = gensim.corpora.Dictionary(gen_docs)\n",
    "print(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1)]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Bag of words. (Lists the number of times each word occurs in the sentence)\"\"\"\n",
    "corpus = [dictionary.doc2bow(gen_doc) for gen_doc in gen_docs]\n",
    "print(corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['fourth', 0.53], ['in', 0.2], ['mars', 0.53], ['our', 0.53], ['solar', 0.2], ['system', 0.2], ['the', 0.2]]\n",
      "[['in', 0.17], ['solar', 0.17], ['system', 0.17], ['the', 0.17], ['after', 0.47], ['it', 0.47], ['mercury', 0.47], ['second-smallest', 0.47]]\n",
      "[['saturn', 0.71], ['yellow', 0.71]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"TFIDF(Term Frequency and Inverse Document Frequency)\n",
    "It is a measure of originality of a word by comparing  the no of times a word appears in a doc with the number of docs the word appears in.\n",
    "Basically words that occur more frequently across the documents get smaller weights\"\"\"\n",
    "\n",
    "tf_idf = gensim.models.TfidfModel(corpus)\n",
    "for doc in tf_idf[corpus]:\n",
    "    print([[dictionary[id], np.around(freq, decimals=2)] for id, freq in doc])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity index with 3 documents in 0 shards (stored under indexdir/)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Creating Similariy Object \n",
    "It builds an index for a given set of documents. The index is split into several smaller sub indexes and saved into disk.\"\"\"\n",
    "\n",
    "sims = gensim.similarities.Similarity('indexdir/', tf_idf[corpus], num_features=len(dictionary))\n",
    "print(sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 1\n",
      "[(0, 1), (3, 1), (6, 1), (9, 2), (14, 1)]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Create  query document \n",
    "need to calculate how similar is the query document to each document in the index. \"\"\"\n",
    "\n",
    "query_docs = []\n",
    "\n",
    "with open(\"demofile2.txt\") as f:\n",
    "    tokens = sent_tokenize(f.read())\n",
    "    for line in tokens:\n",
    "        query_docs.append(line)\n",
    "        \n",
    "print(\"Number of documents:\", len(query_docs))\n",
    "\n",
    "for line in query_docs:\n",
    "    q_doc = [w.lower() for w in word_tokenize(line)]\n",
    "    q_doc_bow = dictionary.doc2bow(q_doc)\n",
    "    print(q_doc_bow)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing Result: [0.11641413 0.10281226 0.56890744]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Document similarities to query\n",
    "As can be seen the third document is most similar \"\"\"\n",
    "q_doc_tf_idf = tf_idf[q_doc_bow]\n",
    "print('Comparing Result:', sims[q_doc_tf_idf]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
